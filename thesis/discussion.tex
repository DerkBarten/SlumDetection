\section{Discussion and Future Work}
We have shown that with our approach, we can detect slums from satellite images to a certain extent. Even though the performance seems low, the result displayed in \ref{fig:res_best} certainly detects areas as slum although there is much noise. As the confusion plot in the same figure indicates, there is a significant number of false positives and false negatives. We will discuss the possible causes the limited performance in the next parts.

\subsection{Features}
In the evaluation section, LSR seemed to be more distinct than HoG; however, HoG seems to achieve higher performance in the classification. Furthermore, in the evaluation of the features, section 1 seemed to perform best, however, in the classification, section 2 is the highest performing section. The performance of RID was, as expected from the feature evaluation, quite poor. It seems that, for HoG and LSR, it does not necessarily entail that a high distinction translates to better performance. However, the number of features could also play a role in this since HoG has about twice as many features as LSR, which might lead us to believe that in this case, quantity superior to quality. Perhaps this counts for the RID as well since this has only a single feature.

Compared to the results obtained by Graesser \textit{et al.} using HoG and LSR, our results seems to be inferior, although it is difficult to compare our results. Firstly, they use accuracy instead of the Matthews coefficient, which could result in entirely different values for the same data. Secondly, the data they used is very different from ours; their paper shows test sections where there is roughly a 50\% class division with clear distinctions between formal and informal areas. Our data is far more imbalanced and less distinct, making a direct comparison in performance unfair. This scarcity and the small scale of our minority class might partially explain why these approaches did not perform at the level observed by Graesser \textit{et al}.

As we have discussed, the performance of RID depends a lot of specific parameters that could be different even within the same image, as we observed with the different sections. Therefore, this approach might not be suitable for use on large scale images as it heavily depends on local road structures, which might be one of the reasons why this feature is lacking in performance compared to the other two features. The adjustment of the parameters to specific image sections might not be worth the effort. Besides the use for slum detection, this method of intersection detection might still be applicable for different problems as it produced accurate detections at relatively low computational cost.

In our case, the combination of the three features did not result in higher performance compared to the individual features. The poor performance of the RID feature might have caused the performance of the feature set to decline, although we have not verified this. Using additional features in combination with HoG and LSR might improve the performance.


\subsection{Classification Algorithms}
The experiment provided insight into the performance of the classifiers using our data, as performance can significantly change depending on the structure of the data. For example, various algorithms might handle high dimensional data well while others are optimized for lower dimensional data; the same principle applies to the class imbalance. Therefore, some classifiers perform better than other classifiers for certain data. Besides the structure of the data, there can be a difference in complexity as well. For instance, the Decision Tree classifier has a low complexity compared to ensemble learners,  such as AdaBoost or Gradient boosting, and might not capture complex relationships in the data. In our case, Gradient boosting seems to produce the highest performance, although there might still be room for improvement. We have only used the default parameters for the classification algorithms, further adjustments in the classifier parameters might improve performance.


\subsection{Scale and Block Size}
We have used three different scales to find out the effects of scale on classification and observed mixed results; it seemed that the performance of increased scale depends on the test image. It is therefore inconclusive what effect the scale has on the classification performance. Besides, the paper of Graesser \textit{et al.} uses a combination of three scales as well, although these scales are in an octave of each other, such as 50, 100 and 200, instead of our 50, 100 and 150, which might cause performance differences.
\newline

\noindent
Besides scales, we have tested different block sizes as well because a large block size without performance loss could significantly reduce computational load. The block size 10, interestingly enough, detected almost no slums for any classifier, neither as true or false positives. It could be that the block size is too small to contain enough information, although we have not verified this. It seems that, in general, performance remains stable when using larger block sizes up to 60, although this did not apply to the Gradient boosting classifier, which experienced a slight decline in performance. Furthermore, we have only tested four different block sizes, further experiments with an increased number of block sizes and different parameters might establish this as a general rule.

The results of the different block sizes might be challenging to compare correctly because a small block size has exponentially more data points than large block sizes, which might lead our measures of performance to penalize small block sizes over large block sizes because large block sizes will have fewer data points. Besides, we qualify a pixel block as a slum when 60\% of the block surface area falls within the boundary of a slum in the shapefile; this introduces a noise on the edges of the slums where some slums are excluded while non-slum might be included. A change in block size might therefore either increase or decrease this noise, making a performance comparison difficult. The extent of these potential factors on performance might be investigated further.

\subsection{Oversampling}
The oversampling methods seem to significantly improve performance relative to the imbalanced dataset. However, because we have only tested this on a single set of parameters, we cannot decisively conclude that oversampling improves performance. Besides oversampling, there are other methods for balancing the dataset that we have not used. With oversampling, we have only used the 1:1 ratio, although a slight minority in slums might reduce false positives. We could also have used outlier detection to detect or reduce the informal class by removing vegetation and open space. 

\subsection{Performance Measures}
We use two indicators for performance, the F1-score and Matthews coefficient, although these methods are not designed for our purposes. The borders of the detected slums could be quite coarse due to the block size, the shapefile or the dynamics of the slums. This could lead to many false classifications even though the position and shape slum might roughly be classified correctly. The predictions should not be penalized on the accuracy of the shape, but encouraged by identifying the correct location and approximately the correct shape by, for instance, finding the center of the predicted slum and calculating the difference to the center of closest ground truth slum. This approach is a promising future direction that is beyond the scope of our thesis.

\subsection{Data}
In the experiments, we used the three sections and did not apply our methods to the entire image as this is beyond the scope of this project. It would be an interesting follow-up experiment as we do not know how the performance will translate to the whole of Bangalore. Furthermore, we could also use different satellite images of different specifications of the same areas to evaluate the impact on classification performance.

\subsection{Final Remarks}
All our code, data, and experiment results are available at \url{https://github.com/DerkBarten/SlumDetection} and is free to use and expand. A description of the architecture and usage is included in the repository as well.
Even though the performance of our method is limited, truly high-performance slum detection methods might become an ethical issue as the locations of slums can both be used to support people in need as well as providing a tool for governments to evict inhabitants from their homes. Even though this thesis is written for academic purposes and has limited performance, it is important to realize that these methods should be used with caution to reduce human suffering instead of causing it.

% Why test image 2 works best?

% strange hog is better

% classifier performance


%Besides that, it is hard to evaluate if the hypothesis for slum detection is correct. This is because we do not know if the hypothesis is false or if the intersection extraction does not produce correct intersections. This is why it is important to have a ground truth of the intersections in the image because this allows to conclude with reasonable certainty if this approach method for slum detection is valid.